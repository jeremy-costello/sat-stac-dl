https://www.eodms-sgdot.nrcan-rncan.gc.ca/stac/collections

sentinel-1 : 75087 items
all data links are .zips
tiffs in here but harder to use

rcm-ard : 11534 items
direct access to tiffs

rcm : 1077757 items
all data links are to order the data


RCM-ARD
RADARSAT Constellation Mission, CEOS-ARD

assets
rl : COG : Backscatter Measurements RL Polarization
rr : COG : Backscatter Measurements RR Polarization
rrrl : COG : Normalized Polarimetric Radar Covariance Matrix (CovMat)
metadata : xml : ARD Product Metadata
data_mask : COG : Data Mask Image
thumbnail : png : Thumbnail
eula_license : pdf : EULA
rl_thumbnail : geotiff : Backscatter RL Polarization Quicklook
rr_thumbnail : geotiff : Backscatter RR Polarization Quicklook
local_inc_angle : COG : Local Incident Angle Image
gamma_to_sigma_ratio : COG : Gamma-to-Sigma Ratio Image
local_contributing_area : COG : Scattering Area Image

the "full" COG is only 96.6GB
https://open.canada.ca/data/en/dataset/f316c469-c068-46f9-a650-95a75f461106/resource/ddca8ee4-d39f-4343-8759-5f87eafa31b8
- this doesn't (really) have a time component though
- also available as a STAC API
  - https://datacube.services.geo.ca/stac/api/search?collections=rcm-ard-mosaic


NOTES
- patch encoding caching? probably not frozen
  - at least patch caching
- position and temporal-specific "position" embedding
- grow dataset over N epochs and then do prioritized replay



PRITHVI
pre-trained on NASA's HLS V2 L30 product (30m granularity) from the contiguous United States
https://planetarycomputer.microsoft.com/dataset/storage/hls
https://nbviewer.org/github/microsoft/AIforEarthDataSets/blob/main/data/hls.ipynb
https://planetarycomputer.microsoft.com/dataset/hls2-l30
https://planetarycomputer.microsoft.com/dataset/hls2-s30


PRITHVI PAPER
https://arxiv.org/abs/2412.02732
- masked auto-encoder
  - based on ViT-L and ViT-H
  - 3D patch and positional embeddings (t,h,w) with t=1 (?????)
- positional embeddings and time/location embeddings are separate?
- models trained for 400 epochs with batch size of 3840
- other hyperparameters
  - weight decay of 0.05
  - LR scheduling
    - linear warmup from 1e-6 to 5e-4 over 40 epochs
    - cosine decay
  - dropout of 0.1
- training samples have 4x256x256 shape (time, width, height)
  - randomly cropped to 4x224x224
  - random horizontal flips (why not vertical too? or even rotations)
- full dataset description in section 2
  - ensuring diverse training samples
    - tiles selected based on LULC
      - copernicus land cover 100m
      - resolve ecoregions
      - 1000 tiles with high LULC entropy
      - is urban in LULC? or based on population or something?
    - images were sampled from tiles
      - dropped all samples with >1% missing values in any band, or >20% cloudy pixels using HLS Fmask
      - missing values were filled with nearest interpolation
      - ensured each patch area has not more than 10 samples
  - 4.2M training and 46k validation samples


DATA PROCESSING
- land cover
  - https://atlas.gc.ca/land-cover/Atlas_LandCover_EN.html
  - https://datacube.services.geo.ca/stac/api/collections/landcover
- collect N samples and have land cover statistics (including entropy between classes)
- oversample small provinces by area
- near-equal sample across area
- how to choose validation tiles? outside of canada?



VISION TRANSFORMER PAPER
https://arxiv.org/abs/2010.11929
- base (86M), large (307M), huge (632M)

MASKED AUTOENCODER PAPER
https://arxiv.org/abs/2111.06377

DINOv3 PAPER
https://arxiv.org/abs/2508.10104
- version trained on satellite imagery (section 8)
  - "Our satellite DINOv3 7B model is pre-trained on SAT-493M, a dataset of 493 millions of 512 Ã— 512 images
    sampled randomly from Maxar RGB ortho-rectified imagery at 0.6 meter resolution"
- https://github.com/facebookresearch/dinov3/issues/34
- https://huggingface.co/facebook/dinov3-vitl16-pretrain-sat493m

GEO-BENCH PAPER
https://arxiv.org/abs/2306.03831
- section 2 is very interesting
  - multispectral with revisits (longitude, latitude, wavelength, time)
  - other sensors: SAR and elevation
  - semantic data (text, non-image data)
- 0.1m to 15m resolution
